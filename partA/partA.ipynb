{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import os\n",
    "import torch\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\DELL\\.netrc\n"
     ]
    }
   ],
   "source": [
    "!wandb login 57566fbb0e091de2e298a4320d872f9a2b200d12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size,img_size):\n",
    "    augmentation = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Load the dataset\n",
    "    data_path = \"../../nature_12K/inaturalist_12K/\"\n",
    "    train_dataset = datasets.ImageFolder(os.path.join(data_path, 'train'), transform = augmentation)\n",
    "    test_dataset = datasets.ImageFolder(os.path.join(data_path, 'val'), transform = augmentation)\n",
    "\n",
    "    \n",
    "    labels = train_dataset.classes\n",
    "    trainset, valset = random_split(train_dataset, [8000, 1999])\n",
    "\n",
    "    train_loader = DataLoader(trainset, batch_size = batch_size)\n",
    "    val_loader = DataLoader(valset, batch_size = batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = batch_size)\n",
    "\n",
    "    return labels , train_loader, val_loader, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently Using ::  cpu\n"
     ]
    }
   ],
   "source": [
    "# CHECK DEVICE (CPU / GPU)\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Currently Using :: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Question - 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CONVOLUTIONAL NEURAL NETWOK CLASS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class ConvolutionalNeuralNetwork(nn.Module):\n",
    "    def __init__(self, PARAM) -> None:\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.filter_org = PARAM[\"filter_org\"]\n",
    "        self.filter_num = PARAM[\"filter_num\"]\n",
    "        self.activation = PARAM[\"activation\"]\n",
    "        self.con_layers = PARAM[\"con_layers\"]\n",
    "        self.den_layers = PARAM[\"dense_layers\"]\n",
    "        self.input_channel = PARAM[\"input_channel\"]\n",
    "        self.filter_num_list = self.organize_filters(self.filter_org, self.filter_num, self.con_layers)\n",
    "        self.filter_size_list = PARAM[\"filter_size\"]\n",
    "        self.act = self.activation_fun(PARAM[\"activation\"])\n",
    "        self.output_act = self.activation_fun(PARAM[\"output_activation\"])\n",
    "        self.padding = PARAM[\"padding\"]\n",
    "        self.stride = PARAM[\"stride\"]\n",
    "        self.pool_padding = PARAM[\"pool_padding\"]\n",
    "        self.pool_stride = PARAM[\"pool_stride\"]\n",
    "        self.dense_output_list = PARAM[\"dense_output_list\"]\n",
    "        self.image_size = PARAM[\"image_size\"]\n",
    "        self.pool_filter_size = PARAM[\"pool_filter_size\"]\n",
    "        self.dropout_list = PARAM[\"dropout\"]\n",
    "        self.create_con_layers(self.input_channel, self.filter_size_list, self.dense_output_list, self.filter_num_list, self.act, self.pool_filter_size, self.output_act, self.image_size, self.dropout_list)\n",
    "        \n",
    "        \n",
    "    def create_con_layers(self, input_channel, filter_size_list, dense_output_list, filter_num_list, act, pool_filter_size, output_act, image_size, dropout_list):\n",
    "        self.layers = nn.ModuleList()\n",
    "        computation = 0\n",
    "        for i in range(1, self.con_layers+1):\n",
    "            comp = 0\n",
    "            layer = nn.Sequential(nn.Conv2d(input_channel, filter_num_list[i-1], filter_size_list[i-1], padding=self.padding, stride=self.stride), act, nn.MaxPool2d(pool_filter_size, padding=self.pool_padding, stride=self.pool_stride), nn.Dropout(dropout_list[i-1]))\n",
    "            \n",
    "            image_size = (image_size - filter_size_list[i-1] + 2 * self.padding)//self.stride + 1\n",
    "            \n",
    "            comp = ((filter_size_list[i-1] ** 2) * input_channel * (image_size ** 2)*filter_num_list[i-1] + filter_num_list[i-1])\n",
    "            computation += comp\n",
    "            image_size = (image_size + 2 * self.pool_padding-(1*(pool_filter_size-1))-1)//self.pool_stride + 1\n",
    "            print(image_size)\n",
    "            # print(comp)\n",
    "            input_channel = filter_num_list[i-1]\n",
    "            self.layers.append(layer)\n",
    "        dense_input = filter_num_list[self.con_layers-1] * (image_size ** 2)\n",
    "        for i in range(1, self.den_layers+1):\n",
    "            comp = 0\n",
    "            layer = nn.Sequential(nn.Linear(dense_input, dense_output_list[i-1]), act, nn.Dropout(dropout_list[self.con_layers + i-1]))\n",
    "            comp = ((dense_input  + 1) * dense_output_list[i-1])\n",
    "            computation += comp\n",
    "            dense_input = dense_output_list[i-1]\n",
    "            self.layers.append(layer)\n",
    "            # print(computation)\n",
    "            # print(comp)\n",
    "        layer = nn.Sequential(nn.Linear(dense_input, 10), output_act)\n",
    "        comp = ((dense_input  + 1) * 10)\n",
    "        computation += comp\n",
    "        # print(comp)\n",
    "        print(\"Computation :: \", computation)\n",
    "        self.layers.append(layer)\n",
    "\n",
    "\n",
    "    def organize_filters(self, filter_org, filter_number, layers):\n",
    "        if filter_org == \"same\":\n",
    "            filter_num = [filter_number] * layers\n",
    "        elif filter_org == \"double\":\n",
    "            filter_num = [filter_number * (2 ** i) for i in range(layers)]\n",
    "        elif filter_org == \"half\":\n",
    "            filter_num = [int(filter_number * (2 ** (-i))) for i in range(layers)]\n",
    "        return filter_num\n",
    "    \n",
    "    \n",
    "    def activation_fun(self, act):\n",
    "        if act == \"ReLU\":\n",
    "            act_fun =nn.ReLU()\n",
    "        elif act == \"GELU\":\n",
    "            act_fun = nn.GELU()\n",
    "        elif act == \"SiLU\":\n",
    "            act_fun = nn.SiLU()\n",
    "        elif act == \"Mish\":\n",
    "            act_fun = nn.Mish()\n",
    "        elif act == \"softmax\":\n",
    "            act_fun = nn.Softmax(dim=1)\n",
    "        elif act == \"ELU\":\n",
    "            act_fun = nn.ELU()\n",
    "        return act_fun\n",
    "    \n",
    "    \n",
    "    def forward(self,x):\n",
    "        for i in range(0, self.con_layers):\n",
    "            x = self.layers[i](x)\n",
    "        x = self.flatten(x)\n",
    "        for i in range(0, self.den_layers):\n",
    "            x = self.layers[i+self.con_layers](x)\n",
    "        x = self.layers[self.con_layers + self.den_layers](x)\n",
    "        return x   \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n",
      "60\n",
      "27\n",
      "11\n",
      "3\n",
      "Computation ::  18213994\n",
      "***********\n",
      "432\n",
      "16\n",
      "2304\n",
      "16\n",
      "2304\n",
      "16\n",
      "2304\n",
      "16\n",
      "2304\n",
      "16\n",
      "4608\n",
      "32\n",
      "320\n",
      "10\n",
      "Total Parameters 14698\n"
     ]
    }
   ],
   "source": [
    "PARAM = {\n",
    "    \"con_layers\" : 5,\n",
    "    \"dense_layers\" : 1,\n",
    "    \"filter_size\" : [3] * 5,\n",
    "    \"output_activation\" : \"softmax\", \n",
    "    \"dense_output_list\" : [32],\n",
    "    \"filter_num\" : 16,\n",
    "    \"activation\" : \"ReLU\",\n",
    "    \"filter_org\" : \"same\", #double half\n",
    "    \"input_channel\" : 3,\n",
    "    \"padding\" : 0,\n",
    "    \"stride\" : 2,\n",
    "    \"pool_padding\" : 0,\n",
    "    \"pool_stride\" : 1,\n",
    "    \"image_size\" : 256,\n",
    "    \"pool_filter_size\" : 3,\n",
    "    \"batch_size\" : 128,\n",
    "    \"eta\" : 0.0001,\n",
    "    \"dropout\" : [0.2] * 6,\n",
    "    \"epochs\" : 5\n",
    "}\n",
    "\n",
    "net = ConvolutionalNeuralNetwork(PARAM)\n",
    "net = net.to(device)\n",
    "print(\"***********\")\n",
    "total = 0\n",
    "for p in net.parameters():\n",
    "    print(p.numel())\n",
    "    total += p.numel()\n",
    "\n",
    "\n",
    "\n",
    "print(\"Total Parameters\", total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image is loading\n",
      "image is loaded\n",
      "Epoch 1, Loss: 0.0365389036753821, Accuracy: 9.375%\n",
      "image is loading\n",
      "image is loaded\n",
      "Epoch 2, Loss: 0.03653850252666171, Accuracy: 9.375%\n",
      "image is loading\n",
      "image is loaded\n",
      "Epoch 3, Loss: 0.036538101377941314, Accuracy: 9.375%\n",
      "image is loading\n",
      "image is loaded\n",
      "Epoch 4, Loss: 0.0365377077980647, Accuracy: 9.375%\n",
      "image is loading\n",
      "image is loaded\n",
      "Epoch 5, Loss: 0.0365373104337662, Accuracy: 9.375%\n",
      "image is loading\n",
      "image is loaded\n",
      "Epoch 6, Loss: 0.03653691306946769, Accuracy: 9.375%\n",
      "image is loading\n",
      "image is loaded\n",
      "Epoch 7, Loss: 0.036536519489591086, Accuracy: 9.375%\n",
      "image is loading\n",
      "image is loaded\n",
      "Epoch 8, Loss: 0.036536133478558254, Accuracy: 9.375%\n",
      "image is loading\n",
      "image is loaded\n",
      "Epoch 9, Loss: 0.03653573611425975, Accuracy: 9.375%\n",
      "image is loading\n",
      "image is loaded\n",
      "Epoch 10, Loss: 0.03653532739669558, Accuracy: 9.375%\n"
     ]
    }
   ],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(net.parameters(), lr = 0.0001)\n",
    "# epochs = 1\n",
    "# labels, train_loader, val_loader, test_loader = load_data(128, PARAM[\"image_size\"])\n",
    "# for epoch in range(epochs):\n",
    "#     net.train()\n",
    "#     running_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     count = 0\n",
    "#     # print(\"image is loading\")\n",
    "#     for images, labels in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = net(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item()\n",
    "#         # print(outputs)\n",
    "        \n",
    "#         # Calculate accuracy\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         # print(_, predicted)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "#         count += 1\n",
    "#         break\n",
    "    \n",
    "#     print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Accuracy: {100 * correct / total}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, PARAM):\n",
    "    wandb.init(project='DL_Assignment2')\n",
    "    wandb.run.name = 'SAMPLE-RUN'\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), PARAM[\"eta\"])\n",
    "    labels, train_loader, val_loader, test_loader = load_data(PARAM[\"batch_size\"], PARAM[\"image_size\"])\n",
    "    for epoch in range(PARAM[\"epochs\"]):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        count = 0\n",
    "        for images, labels in train_loader:\n",
    "            # print(\"image is loaded\")\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            # print(outputs)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # print(_, predicted)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Accuracy: {100 * correct / total}%\")\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                'epochs' : epoch,\n",
    "                'training_loss' : running_loss/len(train_loader),\n",
    "                'training_accuracy' : 100 * correct / total \n",
    "            }\n",
    "        )\n",
    "\n",
    "        wandb.finish()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:r8ifd9g9) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8966484ef472468cadd7dd1d468d89fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epochs</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>training_accuracy</td><td>▁▁▂▁▅▇███▇</td></tr><tr><td>training_loss</td><td>████▆▄▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epochs</td><td>9</td></tr><tr><td>training_accuracy</td><td>14.3</td></tr><tr><td>training_loss</td><td>2.28098</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pretty-snowball-2</strong> at: <a href='https://wandb.ai/cs23m026/DL_Assignment2/runs/r8ifd9g9' target=\"_blank\">https://wandb.ai/cs23m026/DL_Assignment2/runs/r8ifd9g9</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240327_231213-r8ifd9g9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:r8ifd9g9). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Deep_Learning_A2\\DeepLearningA2\\partA\\wandb\\run-20240328_001021-tuemzy56</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs23m026/DL_Assignment2/runs/tuemzy56' target=\"_blank\">devoted-flower-3</a></strong> to <a href='https://wandb.ai/cs23m026/DL_Assignment2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs23m026/DL_Assignment2' target=\"_blank\">https://wandb.ai/cs23m026/DL_Assignment2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs23m026/DL_Assignment2/runs/tuemzy56' target=\"_blank\">https://wandb.ai/cs23m026/DL_Assignment2/runs/tuemzy56</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3025991954500715, Accuracy: 10.2625%\n",
      "Epoch 2, Loss: 2.3026319269150024, Accuracy: 9.7375%\n",
      "Epoch 3, Loss: 2.302504289717901, Accuracy: 9.9125%\n",
      "Epoch 4, Loss: 2.3025629974546886, Accuracy: 10.2125%\n",
      "Epoch 5, Loss: 2.302554274362231, Accuracy: 10.1625%\n"
     ]
    }
   ],
   "source": [
    "train_model(net, device, PARAM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
