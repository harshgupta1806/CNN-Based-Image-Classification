{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import os\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size,img_size):\n",
    "    augmentation = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Load the dataset\n",
    "    data_path = \"../../nature_12K/inaturalist_12K/\"\n",
    "    train_dataset = datasets.ImageFolder(os.path.join(data_path, 'train'), transform = augmentation)\n",
    "    test_dataset = datasets.ImageFolder(os.path.join(data_path, 'val'), transform = augmentation)\n",
    "\n",
    "    labels = train_dataset.classes\n",
    "    trainset, valset = random_split(train_dataset, [8000, 1999])\n",
    "\n",
    "    train_loader = DataLoader(trainset, batch_size = batch_size)\n",
    "    val_loader = DataLoader(valset, batch_size = batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = batch_size)\n",
    "\n",
    "    return labels , train_loader, val_loader, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Question - 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CONVOLUTIONAL NEURAL NETWOK CLASS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class ConvolutionalNeuralNetwork(nn.Module):\n",
    "    def __init__(self, PARAM) -> None:\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.filter_org = PARAM[\"filter_org\"]\n",
    "        self.filter_num = PARAM[\"filter_num\"]\n",
    "        self.activation = PARAM[\"activation\"]\n",
    "        self.con_layers = PARAM[\"con_layers\"]\n",
    "        self.den_layers = PARAM[\"dense_layers\"]\n",
    "        self.input_channel = PARAM[\"input_channel\"]\n",
    "        self.filter_num_list = self.organize_filters(self.filter_org, self.filter_num, self.con_layers)\n",
    "        self.filter_size_list = PARAM[\"filter_size\"]\n",
    "        self.act = self.activation_fun(PARAM[\"activation\"])\n",
    "        self.output_act = self.activation_fun(PARAM[\"output_activation\"])\n",
    "        self.padding = PARAM[\"padding\"]\n",
    "        self.stride = PARAM[\"stride\"]\n",
    "        self.pool_padding = PARAM[\"pool_padding\"]\n",
    "        self.pool_stride = PARAM[\"pool_stride\"]\n",
    "        self.dense_output_list = PARAM[\"dense_output_list\"]\n",
    "        self.image_size = PARAM[\"image_size\"]\n",
    "        self.pool_filter_size = PARAM[\"pool_filter_size\"]\n",
    "        self.create_con_layers(self.input_channel, self.filter_size_list, self.dense_output_list, self.filter_num_list, self.act, self.pool_filter_size, self.output_act, self.image_size)\n",
    "        \n",
    "        \n",
    "    def create_con_layers(self, input_channel, filter_size_list, dense_output_list, filter_num_list, act, pool_filter_size, output_act, image_size):\n",
    "        self.layers = nn.ModuleList()\n",
    "        computation = 0\n",
    "        for i in range(1, self.con_layers+1):\n",
    "            comp = 0\n",
    "            layer = nn.Sequential(nn.Conv2d(input_channel, filter_num_list[i-1], filter_size_list[i-1], padding=self.padding, stride=self.stride), act, nn.MaxPool2d(pool_filter_size, padding=self.pool_padding, stride=self.pool_stride))\n",
    "            \n",
    "            image_size = (image_size - filter_size_list[i-1] + 2 * self.padding)//self.stride + 1\n",
    "            \n",
    "            comp = ((filter_size_list[i-1] ** 2) * input_channel * (image_size ** 2)*filter_num_list[i-1] + filter_num_list[i-1])\n",
    "            computation += comp\n",
    "            image_size = (image_size + 2 * self.pool_padding-(1*(pool_filter_size-1))-1)//self.pool_stride + 1\n",
    "            # print(image_size)\n",
    "            # print(comp)\n",
    "            input_channel = filter_num_list[i-1]\n",
    "            self.layers.append(layer)\n",
    "        dense_input = filter_num_list[self.con_layers-1] * (image_size ** 2)\n",
    "        for i in range(1, self.den_layers+1):\n",
    "            comp = 0\n",
    "            layer = nn.Sequential(nn.Linear(dense_input, dense_output_list[i-1]), act)\n",
    "            comp = ((dense_input  + 1) * dense_output_list[i-1])\n",
    "            computation += comp\n",
    "            dense_input = dense_output_list[i-1]\n",
    "            self.layers.append(layer)\n",
    "            # print(computation)\n",
    "            # print(comp)\n",
    "        layer = nn.Sequential(nn.Linear(dense_input, 10), output_act)\n",
    "        comp = ((dense_input  + 1) * 10)\n",
    "        computation += comp\n",
    "        # print(comp)\n",
    "        print(\"Computation :: \", computation)\n",
    "        self.layers.append(layer)\n",
    "\n",
    "\n",
    "    def organize_filters(self, filter_org, filter_number, layers):\n",
    "        if filter_org == \"same\":\n",
    "            filter_num = [filter_number] * layers\n",
    "        elif filter_org == \"double\":\n",
    "            filter_num = [filter_number * (2 ** i) for i in range(layers)]\n",
    "        elif filter_org == \"half\":\n",
    "            filter_num = [int(filter_number * (2 ** (-i))) for i in range(layers)]\n",
    "        return filter_num\n",
    "    \n",
    "    \n",
    "    def activation_fun(self, act):\n",
    "        if act == \"ReLU\":\n",
    "            act_fun =nn.ReLU()\n",
    "        elif act == \"GELU\":\n",
    "            act_fun = nn.GELU()\n",
    "        elif act == \"SiLU\":\n",
    "            act_fun = nn.SiLU()\n",
    "        elif act == \"Mish\":\n",
    "            act_fun = nn.Mish()\n",
    "        elif act == \"softmax\":\n",
    "            act_fun = nn.Softmax(dim=1)\n",
    "        elif act == \"ELU\":\n",
    "            act_fun = nn.ELU()\n",
    "        return act_fun\n",
    "    \n",
    "    \n",
    "    def forward(self,x):\n",
    "        for i in range(0, self.con_layers):\n",
    "            x = self.layers[i](x)\n",
    "        x = self.flatten(x)\n",
    "        for i in range(0, self.den_layers):\n",
    "            x = self.layers[i+self.con_layers](x)\n",
    "        x = self.layers[self.con_layers + self.den_layers](x)\n",
    "        return x   \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation ::  124318385\n",
      "***********\n",
      "432\n",
      "16\n",
      "1152\n",
      "8\n",
      "288\n",
      "4\n",
      "72\n",
      "2\n",
      "18\n",
      "1\n",
      "1782272\n",
      "32\n",
      "320\n",
      "10\n",
      "Total Parameters 1784627\n"
     ]
    }
   ],
   "source": [
    "PARAM = {\n",
    "    \"con_layers\" : 5,\n",
    "    \"dense_layers\" : 1,\n",
    "    \"filter_size\" : [3] * 5,\n",
    "    \"output_activation\" : \"softmax\", \n",
    "    \"dense_output_list\" : [32],\n",
    "    \"filter_num\" : 16,\n",
    "    \"activation\" : \"Mish\",\n",
    "    \"filter_org\" : \"half\", #double half\n",
    "    \"input_channel\" : 3,\n",
    "    \"padding\" : 0,\n",
    "    \"stride\" : 1,\n",
    "    \"pool_padding\" : 0,\n",
    "    \"pool_stride\" : 1,\n",
    "    \"image_size\" : 256,\n",
    "    \"pool_filter_size\" : 3\n",
    "}\n",
    "\n",
    "net = ConvolutionalNeuralNetwork(PARAM)\n",
    "print(\"***********\")\n",
    "total = 0\n",
    "for p in net.parameters():\n",
    "    print(p.numel())\n",
    "    total += p.numel()\n",
    "\n",
    "\n",
    "\n",
    "print(\"Total Parameters\", total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image is loading\n",
      "image is loaded\n",
      "tensor([0.1526, 0.1525, 0.1529, 0.1530, 0.1525, 0.1524, 0.1526, 0.1522, 0.1521,\n",
      "        0.1526, 0.1523, 0.1519, 0.1525, 0.1530, 0.1527, 0.1530, 0.1527, 0.1524,\n",
      "        0.1529, 0.1527, 0.1528, 0.1529, 0.1526, 0.1533, 0.1530, 0.1528, 0.1526,\n",
      "        0.1529, 0.1522, 0.1523, 0.1524, 0.1529, 0.1525, 0.1523, 0.1522, 0.1522,\n",
      "        0.1523, 0.1525, 0.1530, 0.1519, 0.1525, 0.1521, 0.1523, 0.1523, 0.1527,\n",
      "        0.1529, 0.1524, 0.1531, 0.1528, 0.1527, 0.1525, 0.1522, 0.1526, 0.1532,\n",
      "        0.1522, 0.1526, 0.1526, 0.1524, 0.1521, 0.1524, 0.1527, 0.1524, 0.1528,\n",
      "        0.1523, 0.1526, 0.1528, 0.1523, 0.1526, 0.1524, 0.1524, 0.1527, 0.1525,\n",
      "        0.1525, 0.1524, 0.1527, 0.1526, 0.1524, 0.1524, 0.1528, 0.1525, 0.1527,\n",
      "        0.1523, 0.1525, 0.1522, 0.1530, 0.1524, 0.1530, 0.1524, 0.1521, 0.1522,\n",
      "        0.1523, 0.1526, 0.1528, 0.1525, 0.1529, 0.1526, 0.1526, 0.1526, 0.1526,\n",
      "        0.1523, 0.1529, 0.1524, 0.1525, 0.1524, 0.1523, 0.1535, 0.1529, 0.1528,\n",
      "        0.1527, 0.1526, 0.1523, 0.1521, 0.1524, 0.1526, 0.1525, 0.1525, 0.1525,\n",
      "        0.1520, 0.1527, 0.1528, 0.1526, 0.1525, 0.1520, 0.1522, 0.1526, 0.1524,\n",
      "        0.1523, 0.1530, 0.1525, 0.1528, 0.1527, 0.1523, 0.1526, 0.1528, 0.1525,\n",
      "        0.1524, 0.1523, 0.1527, 0.1526, 0.1522, 0.1528, 0.1526, 0.1527, 0.1525,\n",
      "        0.1526, 0.1522, 0.1519, 0.1529, 0.1522, 0.1524, 0.1528, 0.1524, 0.1516,\n",
      "        0.1527, 0.1527, 0.1526, 0.1532, 0.1523, 0.1527, 0.1527, 0.1525, 0.1525,\n",
      "        0.1529, 0.1523, 0.1522, 0.1525, 0.1528, 0.1537, 0.1530, 0.1526, 0.1525,\n",
      "        0.1531, 0.1527, 0.1523, 0.1520, 0.1528, 0.1527, 0.1525, 0.1524, 0.1527,\n",
      "        0.1529, 0.1532, 0.1522, 0.1524, 0.1525, 0.1521, 0.1527, 0.1524, 0.1523,\n",
      "        0.1529, 0.1523, 0.1529, 0.1527, 0.1526, 0.1530, 0.1522, 0.1526, 0.1526,\n",
      "        0.1523, 0.1523, 0.1526, 0.1524, 0.1520, 0.1521, 0.1521, 0.1522, 0.1521,\n",
      "        0.1524, 0.1530, 0.1524, 0.1523, 0.1523, 0.1523, 0.1525, 0.1525, 0.1535,\n",
      "        0.1526, 0.1525, 0.1525, 0.1528, 0.1523, 0.1523, 0.1531, 0.1525, 0.1532,\n",
      "        0.1524, 0.1522, 0.1525, 0.1523, 0.1525, 0.1525, 0.1534, 0.1525, 0.1530,\n",
      "        0.1525, 0.1523, 0.1530, 0.1520, 0.1523, 0.1528, 0.1528, 0.1523, 0.1526,\n",
      "        0.1528, 0.1527, 0.1529, 0.1527, 0.1523, 0.1525, 0.1524, 0.1526, 0.1528,\n",
      "        0.1526, 0.1524, 0.1525, 0.1523]) tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Epoch 1, Loss: 0.07195095717906952, Accuracy: 10.9375%\n",
      "image is loading\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0001)\n",
    "epochs = 10\n",
    "labels, train_loader, val_loader, test_loader = load_data(256, PARAM[\"image_size\"])\n",
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    count = 0\n",
    "    print(\"image is loading\")\n",
    "    for images, labels in train_loader:\n",
    "        print(\"image is loaded\")\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        # print(outputs)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        print(_, predicted)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        count += 1\n",
    "        break\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Accuracy: {100 * correct / total}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"57566fbb0e091de2e298a4320d872f9a2b200d12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
